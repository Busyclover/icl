---
title: "Introduction to Business Analytics: Assignment Report"
author: "Hoa Giang, Han Mao, Niccolo Valerio, Neha Sharma, Jim Leach"
date: "2 November 2015"
output: pdf_document
---

# People picking

## Problem

For this assignment the group was tasked with using network data collected from the Business Analytics course students to pick three, five-person teams for (1) design; (2) advocacy; and (3) implementation of graduation week plans.

### The catch

The picks were subject to two constraints:

* _Capacity_: Each team must have only five people, and the same individual could not be in more than one team; and
* _Chemistry_: The picks came with a budget. Each team could only use a maximum of 30 "visibility points" (referred to as VPs). These VPs were a proxy for popularity and were derived from a network set up to mimic the social structure of the students.

## Picking teams and this document

The team-picking exercise was carried out and the results presented to the students on the course. This document, therefore, presents the results of some more detailed analysis that was conducted as part of the assignment. 

Four questions were assigned that facilitated further exploration and understanding of the networks. The responses to these questions are presented in this document.

The assignment was competed using the R language. The data were read in to R and the `igraph` package (amongst others) was used to perform the network analysis.

***

\pagebreak

## Assignment Responses

```{r load_packages, message=FALSE, warning=FALSE, echo=FALSE}
  library(MASS)
  library(lsa)
  library(igraph)
  library(readxl)
  library(dplyr)
  library(magrittr)
  library(tidyr)
  library(ggplot2)
  library(knitr)
  library(broom)
  library(stringdist)
  
```

```{r load_data, echo=FALSE}
# get the data
  source("./001_get_data.R")

# define key variables
  back_bone <- 1:57
  dat <- list(albert_hall_links, 
              workshop_links, 
              weekly_meeting_links, 
              urgent_meeting_links)

# create base table
  base <- people %>% 
          left_join(guest_list, by = c("id" = "rater")) %>% rename(guest_list = item) %>% 
          left_join(style, by = c("id" = "rater")) %>% rename(style = item) %>% 
          left_join(option1, by = c("id" = "rater")) %>% rename(option1 = item) %>% 
          left_join(option2, by = c("id" = "rater")) %>% rename(option2 = item)
```

### 1 - Regressions

```{r q1_define_functions, echo=FALSE}
# helper function to extract in-degree centrality
  get_indegrees <- function (data) {
    graph <- graph.data.frame(data, directed = TRUE)
    indegrees <- degree(graph, v = V(graph), mode = "in", loops = FALSE)
    return(indegrees)
  }

# convert network stat to data frame
  convert_stat_to_df <- function(stat){
    stat %>% 
      data.frame() %>%
      add_rownames() %>% 
      setNames(c("id", "stat")) %>% 
      apply(2, as.numeric) %>% data.frame %>% tbl_df
  }   
```

```{r q2_calculate_statistics, echo=FALSE}
# get properties
  indegrees   <- lapply(seq_along(dat), function(x) get_indegrees(dat[x]))

# extract in centrality in node order (1:57) for easier comparisons
  extract_in_order <- function (degrees_obj) {
   sapply(seq_along(back_bone), function(x) degrees_obj[as.character(x)]) 
  }
  ordered_degrees <- sapply(seq_along(indegrees), function(x) 
                          extract_in_order(indegrees[[x]]))

# clean up data in to tidy data frame
  ordered_degrees %<>% data.frame %>% 
                        tbl_df() %>% 
                        add_rownames() %>% 
                        setNames(c("id",
                                   "vp", 
                                   "design", 
                                   "implementation", 
                                   "advocacy"))
  ordered_degrees[is.na(ordered_degrees)] <- 0  # set missing values (i.e. no pick) to 0
```

Negative binomial regression is most suitable as the (count) data have variances greater than their means (Appendix 1). 

```{r q1_fit, echo=FALSE}
# negative binomial models
  fit_pop_to_des_nb <- glm.nb(design ~ vp, ordered_degrees)
  fit_pop_to_imp_nb <- glm.nb(implementation ~ vp, ordered_degrees)
  fit_pop_to_adv_nb <- glm.nb(advocacy ~ vp, ordered_degrees)
  
# create presentation objects
  base_caption1 <- "Regression coefficients from negative binomial regression of"
  base_caption2 <- "on visibility points (vp)"
  col_name <- c("Term", "Estimate", "Std. Error", "Statistic", "p-value")
  
  des_table <- fit_pop_to_des_nb %>% 
                tidy %>% 
                kable(caption = paste(base_caption1, "design in-degree centrality", base_caption2),
                      col.names = col_name)
  
  imp_table <- fit_pop_to_imp_nb %>% 
              tidy %>% 
              kable(caption = paste(base_caption1, "implementation in-degree centrality", base_caption2),
                    col.names = col_name)
  
  adv_table <- fit_pop_to_adv_nb %>% 
              tidy %>% 
              kable(caption = paste(base_caption1, "advocacy in-degree centrality", base_caption2),
                    col.names = col_name)  
  
```

`r des_table`

`r imp_table`

`r adv_table`

The _vp_ coefficient is the change in the log count of in-degree centrality in the other network(s) given a one-unit change in _vp_. 

All models showed a positive, statistically significant relationship between visibility points and the in-degrees centrality in the other networks. 


\pagebreak

### 2 - Cosine Similarity and flexibility

```{r q2_set_up_picks, echo=FALSE}
# set up picks data frame  
picks <- data_frame(id = rep(1:57, each = 57), pick = rep(1:57, 57)) %>% 
          left_join(albert_hall_links, by = c("id" = "rater_id", 
                                              "pick" = "rated_id")) %>% 
          rename(popularity = rating) %>% 
          left_join(workshop_links, by = c("id" = "rater_id", 
                                           "pick" = "rated_id")) %>% 
          rename(design = rating) %>%
          left_join(weekly_meeting_links, by = c("id" = "rater_id", 
                                           "pick" = "rated_id")) %>% 
          rename(implementation = rating) %>%
          left_join(urgent_meeting_links, by = c("id" = "rater_id", 
                                           "pick" = "rated_id")) %>% 
          rename(advocacy = rating)

picks[is.na(picks)] <- 0
```

```{r q2_calc_cosine, echo = FALSE}
# function to get cosine similarity for an id
  get_similarities <- function (data, node) {
      data %>% 
          filter(id == node) %>%
          select(-c(1, 2)) %>% 
          as.matrix() %>% 
          cosine
  }
  
# apply for all ids (returns list of lists)
  similarities <- lapply(seq_along(1:max(picks$id)), 
                         function(x) get_similarities(picks, x))
  
# define function to convert cosine list to matrix for use
  get_cosines <- function (cosine_obj) {
    temp <- cosine_obj %>% 
            unlist %>% 
            matrix(nrow = 4, ncol = 4)
    idx <- lower.tri(temp)
    values <- temp[idx]
    return(values)
  }
  
# get the cosine values
  cosine_values <- lapply(seq_along(similarities), 
                          function(x) get_cosines(similarities[x]))
```  

A higher similarity represents a lower flexibility.
  
The cosine similarities for each ID's picks were calculated and the mean value taken, the value was subtracted from one to give the flexibility score. 

I.e: Flexibility is simply one minus the mean similarity for all pick-vector to pick-vector comparisons for each individual.

```{r q2_aggregate, echo = FALSE}
# aggregate and simplify to give flexiblity score (median cosine value)
  flex_score <- sapply(seq_along(cosine_values), 
                       function(x) mean(cosine_values[[x]], na.rm = T)) %>% 
                data.frame() %>%
                add_rownames() %>% 
                setNames(c("id", "flex")) %>%
                mutate(flex = 1-flex) %>% 
                tbl_df() %>% 
                mutate(z = (flex - mean(flex, na.rm = TRUE))/sd(flex, na.rm = TRUE)) %>% 
                arrange(-flex) %>% 
                apply(2, as.numeric) %>% 
                data.frame %>% tbl_df
# print pretty
  kable(flex_score, caption = "Flexibility score and Z-value for all 57 individuals in the class",
        col.names = c("ID", "Flexibility", "Z"))  
```  

\pagebreak

### 3 - Determining group leaders

```{r q3, echo = FALSE}
  teams <- read_excel("./data/analysis_normalised_20151101_ver2.xlsx", 
                      sheet = "tot") %>% 
            tbl_df %>% 
            filter(des_pick == 1 | imp_pick == 1 | adv_pick == 1) %>% 
            select(id, des_pick, imp_pick, adv_pick)

# join on to flexibility scores    
  flex_score_leaders <- flex_score %>% 
                        left_join(base, by = "id") %>% 
                        left_join(teams, by = "id") %>% 
                        mutate(additional_flex = ifelse(option1 != 0 & 
                                                        option1 != style, 1, 0)) %>% 
                        select(id, flex, z, additional_flex, option2, 
                               des_pick, imp_pick, adv_pick)
# get tables
  des_tbl <- flex_score_leaders %>% 
              filter(des_pick == 1) %>% 
              mutate(score_adj = flex + additional_flex + option2) %>% 
              select(id, flex, z, additional_flex, option2, score_adj) %>% 
              rename(mix_invite = additional_flex,
                     mix_prop = option2)
  
  imp_tbl <- flex_score_leaders %>% 
              filter(imp_pick == 1) %>% 
              mutate(score_adj = flex + additional_flex + option2) %>% 
              select(id, flex, z, additional_flex, option2, score_adj) %>% 
              rename(mix_invite = additional_flex,
                     mix_prop = option2)
  
  adv_tbl <- flex_score_leaders %>% 
              filter(adv_pick == 1) %>% 
              mutate(score_adj = flex + additional_flex + option2) %>% 
              select(id, flex, z, additional_flex, option2, score_adj) %>% 
              rename(mix_invite = additional_flex,
                     mix_prop = option2)  
  
# find team leaders  
  des_lead <- des_tbl %>% 
              filter(score_adj == max(score_adj, na.rm = TRUE))
  
  imp_lead <- imp_tbl %>% 
              filter(score_adj == max(score_adj, na.rm = TRUE))
  
  adv_lead <- adv_tbl %>% 
              filter(score_adj == max(score_adj, na.rm = TRUE))
  
leaders <-   bind_rows(des_lead, imp_lead, adv_lead) %>% 
              mutate(Team = c("Design", "Implementation", "Advocacy")) %>% 
              rename(ID = id, Flex = flex, Z = z) %>% 
              select(Team, ID, score_adj, Z)
```

Personalities also affect flexibility.

Individual were assigned additional flexibility points based on their personality quiz responses:

```{r add_points_tbl, echo = FALSE}
extra <- data.frame(Choice = c("Host a party with different invitation methods",
                               "Use preferred method of invitation",
                               "Use a 50/50 split of invitation methods"),
                    AddPoints = c(1, 1, 2))
kable(extra, caption = "Additional flexiblity point awards", 
      col.name = c("Criteria", "Bonus points awarded"))
```

The adjusted scores for each team were:

```{r kable_adjusted_scores, echo = FALSE}
fields <- c("ID", "Original Flexibility", "Z", "Mixed Invite Bonus", "Mix Proportion Bonus", "Adjusted Flexiblity")
kable(des_tbl, col.names = fields, caption = "Design team flexiblity scores and adjustments", digits = 3)
kable(imp_tbl, col.names = fields, caption = "Implementation team flexiblity scores and adjustments", digits = 3)
kable(adv_tbl, col.names = fields, caption = "Advocacy team flexiblity scores and adjustments", digits = 3)
```

\pagebreak

The three IDs with the highest flexibility in each team were selected to be leaders:

```{r q3_leaders, echo = FALSE}
kable(leaders, caption = "Team leaders based on flexibility scores", 
      col.names = c("Team", "ID", "Adjusted Flexiblity Score", "Original Z"))
```

\pagebreak

### 4 ID Rankings

```{r q4_prep, echo=FALSE}
design <- read_excel("./data/design.xlsx") %>% 
            mutate(score = 0.6 * bet + 0.3 * eig + 0.1 * close,
                   ratio = score / vp) %>% 
            select(id, score, vp, ratio) %>% 
            arrange(-ratio)

# impelementation
implementation <- read_excel("./data/implementation.xlsx") %>% 
                  mutate(score = 0.1 * bet + 0.3 * eig + 0.6 * close,
                         ratio = score / vp) %>% 
                  select(id, score, vp, ratio) %>% 
                  arrange(-ratio)
  
# advocacy
advocacy <- read_excel("./data/advocacy.xlsx") %>% 
                mutate(score = 0.4 * bet + 0.4 * eig + 0.2 * close,
                       ratio = score / vp) %>%  
                select(id, score, vp, ratio) %>% 
                arrange(-ratio)
```

The "benefit" in each network were the design, implementation and advocacy scores used for picking. This measure was chosen as it best represents each node's value in that network, as chosen by its peers.

* $Design = 0.6 Betweenness + 0.3 Eigenvector centrality + 0.1 Closeness$
* $Implementation = 0.1 Betweenness + 0.3 Eigenvector centrality + 0.6 Closeness$
* $Advocacy = 0.4 Betweenness + 0.4 Eigenvector centrality + 0.2 Closeness$

Having defined these formulae, the measure-of-value (which is defined as $score/visibility points$) scores are:

```{r q4_tables, echo = FALSE}
col_names <- c("ID", "Network Score", "Visibility Points", "Measure of Value (cost-benefit)")
kable(design, caption = "Design network measure of value", col.names = col_names)
kable(implementation, caption = "Implementation network measure of value", col.names = col_names)
kable(advocacy, caption = "Advocacy network measure of value", col.names = col_names)
```

### 5 - Bonus

Cosine similarity is just one method for developing a flexibility score. An alternative is to use the _Jaccard similarity_ which can be used to compare the similarity between two potentially overlapping sets. The Jaccard similarity score is given by \eqref{eq:jaccard}. 

\begin{equation} \label{eq:jaccard}
J(A, B) = \dfrac{|A\cap B|}{|A \cup B|}
\end{equation}

In \eqref{eq:jaccard} it is seen that the similarity of two sets can be calculated by comparing the relative difference in their [intersection](https://en.wikipedia.org/wiki/Intersection_%28set_theory%29) and [union](https://en.wikipedia.org/wiki/Union_%28set_theory%29). 

As with cosine similarity, to represent flexibility in picks, it is more desirable to represent how _dissimilar_ two sets of picks are. This can be performed using the _Jaccard Distance_ \eqref{eq:j_dist} which is simply one minus the Jaccard Similarity.

\begin{equation} \label{eq:j_dist}
d_{j}(A,B) = 1 - J(A, B) = \dfrac{|A\cup B| - |A\cap B|}{|A\cup B|}
\end{equation}

It should be noted that the Jaccard similarity can be adjusted to also compute differences between (0, 1) vectors, however this was not done in this case. Treating each individuals' picks on each network as a different set, the Jaccard distance was calculated for each possible combination (e.g. popularity with design, implementation, and advocacy; design with implementation and advocacy etc).

```{r bonus_get_jaccards, echo = FALSE, warning=FALSE}
get_jaccard <- function ( data1, data2, data3, data4, node) {
  tmp1 <- data1 %>% dplyr::select(-rating) %>%  filter(rater_id == node) %>% dplyr::select(rated_id) %>% unlist %>% as.numeric()
  tmp2 <- data2 %>% dplyr::select(-rating) %>%  filter(rater_id == node) %>% dplyr::select(rated_id) %>% unlist %>% as.numeric()
  tmp3 <- data3 %>% dplyr::select(-rating) %>%  filter(rater_id == node) %>% dplyr::select(rated_id) %>% unlist %>% as.numeric()
  tmp4 <- data4 %>% dplyr::select(-rating) %>%  filter(rater_id == node) %>% dplyr::select(rated_id) %>% unlist %>% as.numeric()
  
  one_four <- seq_sim(tmp1, tmp4, method = "jaccard")
  one_three <- seq_sim(tmp1, tmp3, method = "jaccard")
  one_two <- seq_sim(tmp2, tmp2, method = "jaccard")
  
  two_four <- seq_sim(tmp2, tmp4, method = "jaccard")
  two_three <- seq_sim(tmp3, tmp3, method = "jaccard")
  
  three_four <- seq_sim(tmp3, tmp4, method = "jaccard")
  
  return(mean(c(one_four, one_three, one_two, two_four, two_three, three_four)
              , na.rm = T))
          
}

jaccards <- sapply(1:57, function(x) 
                  get_jaccard(albert_hall_links, workshop_links,
                              urgent_meeting_links, weekly_meeting_links, x)) %>% 
            data.frame() %>% 
            add_rownames() %>% 
            apply(2, as.numeric) %>% 
            data.frame %>% tbl_df %>% setNames(c("id", "mean_jaccard"))
```

To give a single-value "score" for each ID, the mean value of the Jaccard distance between their pick sets was taken.

Additionally, the Jaccard-based   flexibility score was transformed using the average number of picks made by each ID in each network, relative to the the total number of picks possible in each network. The total possible picks for an ID in each network was 6. Therefore, for each network the proportion of selected picks was calculated using $picks / possible picks$. For example this would return a value of `r 4/6` for an individual who selected four picks out of a possible six. Again, to return a single-value score, the mean "pick proportion" across the four networks was calculated for each ID.

```{r bonus_get_proportions, echo = FALSE}
possible_picks <- 6
get_picks_over_poss <- function (data, node,  max_picks = 6) {
  tmp <- data %>% 
    filter(id == node) %>%
    dplyr::select(-c(id, pick)) %>% 
    apply(2, sum)
  tmp / possible_picks
}

picks_over_poss <- lapply(seq_along(1:max(picks$id)), 
                       function(x) get_picks_over_poss(picks, x, possible_picks))

avg_picks_over_poss <- sapply(1:57, function(x) 
                                    mean(picks_over_poss[[x]], na.rm = T)) %>% 
                        data.frame() %>% 
                        add_rownames() %>% 
                        apply(2, as.numeric) %>% 
                        data.frame() %>% tbl_df() %>% 
                        setNames(c("id", "picks_over_poss"))
```

This was then combined with the Jaccard distance scores and an overall flexibility score derived by multiplying the mean Jaccard distance for each ID's picks by the mean "picks proportion score" derived above \eqref{eq:j_flex}. In this way, ID's were penalised for choosing fewer picks in each network. 

\begin{equation} \label{eq:j_flex}
Flexiblity_{Jaccard} = mean(d_j (A, b)) * mean(\dfrac{picks}{possible picks}) 
\end{equation}

This was done as, for two IDs with the same mean Jaccard distance, a higher flexibility score should be assigned to the ID that made 6 picks in each network than the ID that made 1 pick in each network (i.e. not picking does not equate to more flexiblity!).

```{r bonus_combine_picks_with_jaccard, echo = FALSE}
flex_bonus <- jaccards %>% 
              left_join(avg_picks_over_poss, by = "id") %>% 
              mutate(flex_score = mean_jaccard * picks_over_poss,
                     flex_score = ifelse(mean_jaccard == 0 & picks_over_poss == 0,
                                         NA, flex_score),
                     flex_score_adj = (1-flex_score) * picks_over_poss,
                     z = (flex_score_adj - mean(flex_score_adj, na.rm = T))/sd(flex_score_adj, na.rm = T)) %>% 
              select(id, flex_score_adj, z) %>% 
              left_join(flex_score %>% mutate(rank = row_number(-flex)), by = "id") %>% 
              rename(new_flex = flex_score_adj,
                     z_new = z.x,
                     old_flex = flex,
                     z_old = z.y,
                     rank_old = rank) %>%
              mutate(rank_new = row_number(-new_flex),
                     shift = rank_old - rank_new) %>% 
              arrange(-new_flex)
```

The previous flexibility score calculated using cosine similarity was then compared with the score derived with the Jaccard method. The results are presented overleaf (note that only IDs that actually made picks are shown).

Some similarities and some differences in the score are observed. Some IDs remain relatively unchanged in their flexibility, for example, ID 29 remained in second place having chosen different sets of IDs in each network. ID 44, however, increased it's rank from 4 to 1. This is due to the fact that in the cosine model developed earlier, no weighting for the number of picks was used. ID 44 picked 6 different individuals in each team whereas ID 29 picked only five members for the Royal Albert Hall and for implementation. Hence in the Jaccard scoring method the score for ID 29 was down-weighted pulling it below ID 44. 

Some further similarities can be observed for IDs that made very few picks, again based on the weighting for number of picks made. For example, ID 4 made just 3 picks in the Royal Albert Hall network, 0 picks for design, 3 picks for implementation and 0 picks for advocacy. 

When ID 4's pick vectors were compared with cosine similarity, the all-0 vectors generated by the design and popularity picks caused the distances to degenerate and the resulting cosine similarity is returned as `NaN`, i.e. "not a number" (reference [here](http://stats.stackexchange.com/a/30008)). The 3 picks for the Royal Albert Hall and for popularity were the same (cosine similarity of 1). When calculating the mean cosine similarity, the `NaN` values were ignored and therefore ID 4 generated a mean cosine similarity of 1, and hence a very low flexibility score.

However when using the Jaccard similarity to compare the differences in the _sets_ of picks (as opposed to the (0, 1) pick _vectors_) the sets where no picks were made (equivalent to the all-0 vectors in the cosine method) did not cause any degeneracy and returned a Jaccard similarity of 0. Therefore, when taking the mean, the no-pick sets came in to play. They simply down-weighted the Jaccard similarity score for ID 4. Using the formula in \eqref{eq:j_dist}, this generated a mean Jaccard distance of `r 1-round(get_jaccard(albert_hall_links, workshop_links, urgent_meeting_links, weekly_meeting_links, 4), 3)`, which seemed high. However this "artificial inflation" was accounted for using the number of picks weighting. Given that ID 4 had an average "picks proportion"  of `r round(mean(c(3/6, 0/6, 3/6, 0/6)), 3)`, the overall Jaccard-based flexibility score was dropped to just `r round(flex_bonus[flex_bonus$id == 4, 2], 3)`.

In this way the two methods are relatively similar. Whilst the weighting for the "picks proportion" is qualitatively sensible, it does not have a significant impact on the quantitative results.

It is possible that in the presence of an all-0 pick vector, the Jaccard method produces better results. As was discussed above, when using the cosine method, all-0 pick vectors result in degeneracy problems that do not occur with the Jaccard method. However, this is a data completeness issue (in this instance) and, were additional data collected, would not necessarily be a factor in distinguishing the superior method. It is therefore not possible to conclude, with certainty, the either method is "better" than the other. 

\pagebreak

```{r bonus_present, echo = FALSE}
flex_bonus %>% 
na.omit %>% 
  kable(caption = "Cosine and Jaccard flexibility scores and Z-values for IDs which made picks",
        col.names = c("ID", "Jaccard Flexibility", "Jaccard Z",
                      "Cosine Flexiblity", "Cosine Z",
                      "Cosine rank", "Jaccard Rank", "Shift"),
        digits = 3)
```

***

\pagebreak

## Appendices

### Appendix One - Exploratory plot of in-degree centrality distributions

```{r appendix1, echo = FALSE}
ordered_degrees[, -1] %>% 
  rename(Popularity = vp,
         Design = design,
         Implementation = implementation,
         Advocacy = advocacy) %>% 
      gather() %>% 
      ggplot(aes(x = value)) +
      geom_histogram(aes(fill = key), colour = "white", binwidth = 1) +
      facet_grid(key ~ .) +
      xlab("In-Degree centrality") +
      ylab("Count") +
      theme(legend.position = "none",
            strip.background = element_rect(fill = "gray80"),
            panel.background = element_rect(fill = "gray99", colour = "gray75"),
            panel.grid.major.y = element_line(colour = "gray85"),
            panel.grid.major.x = element_blank())

cbind(c("Mean", "Variance"),
      rbind(apply(ordered_degrees[, 2:5], 2, mean),
      apply(ordered_degrees[, 2:5], 2, var))) %>% 
kable(caption = "Means and variances for in-degrees centrality accross the four networks",
      col.names = c("Statistic", "Popularity", "Design", "Implementation", "Advocacy"))
            
```  

As the data are count data, and the conditional variances of the distributions were much larger than the conditional means, negative binomial regression was chosen as the most suitable method for this regression problem.

\pagebreak

### Appendix Two - OLS Linear Regression Results
```{r appendix2, echo=FALSE}
# OLS linear models
  fit_pop_to_des <- lm(design ~ vp, ordered_degrees)  
  fit_pop_to_imp <- lm(implementation ~ vp, ordered_degrees)  
  fit_pop_to_adv <- lm(advocacy ~ vp, ordered_degrees)
  
# create presentation objects
  lm_base_caption1 <- "Regression coefficients from linear regression of"
  lm_base_caption2 <- "on visibility points (vp)"
  col_name <- c("Term", "Estimate", "Std. Error", "Statistic", "p-value")
  
  des_table_lm <- fit_pop_to_des %>% 
                tidy %>% 
                kable(caption = paste(lm_base_caption1, "design picks", base_caption2),
                      col.names = col_name)
  
  imp_table_lm <- fit_pop_to_imp %>% 
              tidy %>% 
              kable(caption = paste(lm_base_caption1, "implementation picks", base_caption2),
                    col.names = col_name)
  
  adv_table_lm <- fit_pop_to_adv %>% 
              tidy %>% 
              kable(caption = paste(lm_base_caption1, "advocacy picks", base_caption2),
                    col.names = col_name)   
```

`r des_table_lm`

`r imp_table_lm`

`r adv_table_lm`

Linear models all reveal a statistically significant, positive relationship between visibility points and picks elsewhere. These models were assessed with data of size `r nrow(ordered_degrees)` and have $R^2$ values of `r round(summary(fit_pop_to_des)$r.squared, 3)`, `r round(summary(fit_pop_to_imp)$r.squared, 3)`, `r round(summary(fit_pop_to_adv)$r.squared, 3)` respectively.