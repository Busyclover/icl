---
title: "Statistics and Econometrics - Assignment Three"
author: "Jim Leach"
date: "28 October 2015"
output: pdf_document
---

# Document purpose

The purpose of this document is to write up the response to the third assignment given as part of the _Statistics and Econometrics_ module. It is divided in to two sections, each covering a section of the assignment as given. Each major section is divided in to further subsections, one for each question in the assignment.

A number of `R` packages have been used throughout this assignment. These are loaded before the responses are given:

```{r load_pkg, echo = TRUE, message = FALSE}
library(dplyr)
library(magrittr)
library(broom)
library(knitr)
library(car)
```

***

# Section 1

In this section, it is posited that data from a survery on wages, education, experience and gender is provided. In addition, data on marijuana use is also asked for. The question asked regarding marijuana use was:

> "On how many separate occasions last month did you smoke marijuana?"

## 1a

\begin{equation} \label{eq:1a}
log(wage) = \beta_0 + \delta_1 female + \beta_1 education + \beta_2 experience + \beta_4 marijuana + u
\end{equation}

If it is assumed that:

* gender is represented by a binary variable (named $female$) whereby a value of $1$ indicates female, and $0$ indicates male; and
* education, experience and marijuana are purely quantitaive variables named as such

then a simple equation such as \eqref{eq:1a} can be written to allow statements such as "Smoking marijuana five more times per month is estimated to change wage by x%". Note that the dummy variable $female$ contrasts the change in wage between genders (holding the other independant constant) with males as the base group.

## 1b

\begin{equation} \label{eq:1b}
log(wage) = \beta_0 + \delta_1 female + \beta_1 education + \beta_2 experience + \beta_3 marijuana + \delta_2 marijuana.female + u
\end{equation}

The regression function given in \eqref{eq:1b} would allow a test to be performed to understand if drug (marijuana) use has a different effect on wage for men and women. In \eqref{eq:1b} it is the $\delta_2$ parameter that describes this effect, it is the estimated change in the slope coefficient for marijuana use ($\beta_3$) for females over the reference group (males).

It would be possible to test that there are no differences in the effects of drug usage for men and women using the following hypothesis:

* $H_0:\delta_1 = 0$ and $\delta_2 = 0$, i.e. the wage is the same for men and women who have the same level of drug use.

For this hypothesis, an $F$-statistic could be generated to test for exclusion restrictions. 

## 1c


\begin{equation} \label{eq:1c}
log(wage) = \beta_0 + \delta_1marijuana + \beta_1 education + \beta_2 experience
\end{equation}


In this example gender is omitted (for simplicity's sake), as are interaction terms between marijuana use and the other variables. It is assumed that marijuana use is given by a categorical factor variable with four levels:

1. nonuser (0 uses per month);
1. light user (1 to 5 uses per month);
2. moderate user (6 to 10 uses per month); and
4. heavy user (greater than 10 uses per month).

In the equation given by \eqref{eq:1c} the effect of marijuana use on wage is given by $\delta_1$. A fuller and more explicit regression function could also be given by:

\begin{equation} \label{eq:1c_2}
log(wage) = \beta_0 + \delta_0 light + \delta_1 medium + \delta_2 heavy + ... + u
\end{equation}

In equation \eqref{eq:1c_2}, the "..." term represents the other variables included in \eqref{eq:1c} but omitted here for brevity. In \eqref{eq:1c_2}, $\beta_0$ represents the estimated wage for nonusers holding the other variables constant, $\delta_0$ represents the change for light users, $\delta_1$ for medium users and $\delta_2$ for heavy users.

## 1d

To test the null hypothesis that marijuana usage has no effect on wage is done using an $F$ statistic. In this instance, _marijuana use_ is not well defined and as such it is assumed that this means that the null is that _any_ use of marijuana has no effect on wage. 

As such, this is best understood using \eqref{eq:1c_2} to test for multiple linear restrictions in the $\delta$ parameters of the marijuana dummy variable. To do so, an __unrestricted__ model is defined (again, gender is omitted for simplicity's sake).

\begin{equation} \label{eq:1d_ur}
log(wage) = \beta_0 + \delta_0 light + \delta_1 medium + \delta_2 heavy + \beta_1 education + \beta_2 experience + u
\end{equation}

In order to test the null that marijuana usage has no effect on wage it is also necessary to construct the __restricted model__ that describes this.

\begin{equation} \label{eq:1d_r}
log(wage) = \beta_0 + \beta_1 edcuation + \beta_2 experience + u
\end{equation}

The restricted model \eqref{eq:1d_r} will allow the null $H_0: \delta_0 = 0$ and $\delta_1 = 0$ and $\delta_2 = 0$ to be tested.

In order to do this, the $F$ statistic is computed.

\begin{equation} \label{eq:1d_fstat}
F = \dfrac{(SSR_r - SSR_{ur})/q}{SSR_{ur}/(n-k-1)}
\end{equation}

In \eqref{eq:1d_fstat} $SSR_r$ and $SSR_{ur}$ represent the sum of squared residuals from the restricted and unrestricted models respectively, $q$ is the number of restrictions and $n-k-1$ is the degrees of freedom in the unrestricted model. 

Having calculated the $F$ statistic, a critical value is defined for the desired significance level using an $F$ distribution with $df1 = q$ and $df2 = n-k-1$. If the $F$ statistic calulcated is greater than or equal to this critical value then the null can be rejected, i.e. it is possible to state that marijuana use _does_ have a statistically significant effect on wage. This is independant of an individual dosage of marijuana (i.e. light/medium/heavy) and instead considers the __joint effect__ of the three doses on wage.

## 1e

Some potential problems with drawing causal inferences using the survey data collected are self selection problems. It may be the case that people who use marijuana are less likely (or more likely) to respond to the survey, leading to a potentially biased sample. 

Furthermore, there may be issues of multicollinearity between marijuana use and the other explanatory variables (for example it may be the case that men are more likely to use marijuana, or that people who use marijuana have lower levels of education on average).

Moreoever, there may be many variables that are included in the error term that have a (high) correlation with marijuana use (e.g. socio-economic status, ethnicity) but that could have a significant impact on wage. By not explicitly including these in the model it is possible that the ZCM assumption will not hold and as such it could be hard to draw causal inferences from the data.

***

\pagebreak

# Section two

In this section data concerning basketball statistics are provided and some linear models built to investigate relationships in the data. Firstly, the data are loaded and some preparation performed for later calculations.

```{r 2load}
load("./data/nbasal.RData")

# create a dummy variable with centre as reference level
# and a clean married factor variable with pretty labels
data %<>% mutate(pos = factor(ifelse(guard == 1, "guard", 
                              ifelse(forward == 1, "forward", "center")),
                              levels = c("center", "forward", "guard")),
                 marr_fac = factor(marr, labels = c("unmarried", "married")))
```

A quick exploration of the data was performed and it was found that missing values were present only in the $draft$ field. As this field will not be used for this assigment, no action was taken regarding this.

## 2a

```{r 2a_prep}
# fit the model and call summary
fit_2a <- lm(points ~ pos + exper + expersq, data)
fit_2a_summ <- fit_2a %>% summary
fit_2a_tidy <- fit_2a %>% tidy

# make a pretty table
fit_2a_tidy %>% kable(caption = "Regression coefficients from linear model of points regressed on position and experience")
```


In addition to the above table of regression coefficients, the $R^2$ value for the fitted model is `r round(fit_2a_summ$r.squared, 2)` and the sample size is `r nrow(data)`. This leads to the SRF:

\begin{equation} \label{eq:2a}
\begin{split}
points = \beta_0 + \delta_0forward + \delta_1guard + \beta_1exper + \beta_2exper^2 +\hat{u} \\
points = `r round(fit_2a_tidy[1, 2], 3)` + `r round(fit_2a_tidy[2, 2], 3)`forward + `r round(fit_2a_tidy[3, 2], 3)`guard + `r round(fit_2a_tidy[4, 2], 3)`exper + `r round(fit_2a_tidy[5, 2], 3)`exper^2 + \hat{u}
\end{split}
\end{equation}

## 2b

Using the output from the regression in 2a and the SRF given in \eqref{eq:2a}, holding experience fixed, a guard scores approximately `r round(fit_2a_tidy[3, 2], 3)` points more than a centre. This value is significant with a $p$ value of `r round(fit_2a_tidy[3, 5], 3)`.

## 2c

```{r 2c}
# create a nicer looking marriage factor
fit_2c <- lm(points ~ pos + exper + expersq + marr_fac, data)
fit_2c_summ <- fit_2c %>% summary
fit_2c_tidy <- fit_2c %>% tidy

# make a pretty table
fit_2c_tidy %>% kable(caption = "Regression coefficients from linear model of points regressed on position, experience and marital status")
```

In addition to the above table of regression coefficients, the $R^2$ value for the fitted model is `r round(fit_2c_summ$r.squared, 2)` and the sample size is `r nrow(data)`. This leads to the SRF:

\begin{equation} \label{eq:2c}
\begin{split}
points = \beta_0 + \delta_0forward + \delta_1guard + \beta_1exper + \beta_2exper^2 + \delta_2married + \hat{u} \\
points = `r round(fit_2c_tidy[1, 2], 3)` + `r round(fit_2c_tidy[2, 2], 3)`forward + `r round(fit_2c_tidy[3, 2], 3)`guard + `r round(fit_2c_tidy[4, 2], 3)`exper + `r round(fit_2c_tidy[5, 2], 3)`exper^2 + `r round(fit_2c_tidy[6, 2], 3)`married + \hat{u}
\end{split}
\end{equation}

According to this regression, married players are more productive with an additional `r round(fit_2c_tidy[6, 2], 3)` points scored per game. However, this value is not statistically significant with a $p$ value of `r round(fit_2c_tidy[6, 5], 3)`. As such it is not possible to conclude, with certainty, that married players are more productive at a statistically significant level.

\pagebreak

## 2d

```{r 2d}
fit_2d <- lm(points ~ pos + exper + expersq + marr_fac + exper:marr_fac + expersq:marr_fac, data)
fit_2d_summ <- fit_2d %>% summary
fit_2d_tidy <- fit_2d %>% tidy
fit_2d_tidy %>% kable(caption = "Regression coefficients from linear model of points regressed on position, experience and marital status, with an interaction between experience and marital status")
```



In addition to the above table of regression coefficients, the $R^2$ value for the fitted model is `r round(fit_2d_summ$r.squared, 2)` and the sample size is `r nrow(data)`.

In this expanded model, the effect of marital status at a given level of experience is to add approximately `r round(fit_2d_tidy[7, 2], 3)` points per game. However, this value is not statistically significant with a $p$ value of `r round(fit_2d_tidy[7, 5], 3)`.

Additionally, an $F$ statistic can be calulcated to determine if there is a statistically significant relationship between marrital status and points scored, inclusive of the interaction with experience.

```{r 2d_fstat}
f_stat <- linearHypothesis(fit_2d, c("marr_facmarried = 0",
                                     "exper:marr_facmarried = 0",
                                     "expersq:marr_facmarried = 0"))

```

In this case, it appears again that there is _not_ strong evidence that marital status affects points scored per game, with a $F$ statistic of `r round(f_stat$F[2], 3)` and an associated $p$ value of `r round(f_stat$"Pr(>F)"[2], 3)`.

## 2e 

```{r}
# create a nicer looking marriage factor
fit_2e <- lm(assists ~ pos + exper + expersq + marr_fac, data)
fit_2e_summ <- fit_2e %>% summary
fit_2e_tidy <- fit_2e %>% tidy

# compare effect of position
fit_2c_fstat <- linearHypothesis(fit_2c, c("posforward = 0", "posguard = 0"))
fit_2e_fstat <- linearHypothesis(fit_2e, c("posforward = 0", "posguard = 0"))

# make a pretty table
fit_2e_tidy %>% kable(caption = "Regression coefficients from linear model of assists regressed on position, experience and marital status")
```


In addition to the above table of regression coefficients, the $R^2$ value for the fitted model is `r round(fit_2e_summ$r.squared, 2)` and the sample size is `r nrow(data)`. This leads to the SRF given below:

\begin{equation} \label{eq:2e}
\begin{split}
assists = \beta_0 + \delta_0forward + \delta_1guard + \beta_1exper + \beta_2exper^2 + \delta_2married + \hat{u} \\
points = `r round(fit_2e_tidy[1, 2], 3)` + `r round(fit_2e_tidy[2, 2], 3)`forward + `r round(fit_2e_tidy[3, 2], 3)`guard + `r round(fit_2e_tidy[4, 2], 3)`exper + `r round(fit_2e_tidy[5, 2], 3)`exper^2 + `r round(fit_2e_tidy[6, 2], 3)`married + \hat{u}
\end{split}
\end{equation}

Looking at the individual coefficients for this model, it seems that when the relationship between _assists_ and position is assessed there is a statistically significant relationship, which was not present in the relationship between _points_ and position. 

This is backed up by an $F$-statistic test for the two models (i.e. one for the points model and one for the assists model). 

In the points model from 2c, it was found that position did _not_ have a statistically significant effect on points scored ($F$-statistic = `r round(fit_2c_fstat$F[2], 3)` and associated $p$-value = `r round(fit_2c_fstat$"Pr(>F)"[2], 3)`).

In the assists model from 2e, it was found that position _did_ have a statistically significant effect on points scored ($F$-statistic = `r round(fit_2e_fstat$F[2], 3)` and associated $p$-value = `r round(fit_2e_fstat$"Pr(>F)"[2], 3)`).








